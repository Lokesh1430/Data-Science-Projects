{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c73004-22a1-48c1-9002-7def01c3a200",
   "metadata": {},
   "source": [
    "<h4 style=\"color: #00698f; font-weight: bold; text-align: center;\"> <span style=\"color: #2ecc71;\">DATA</span> <span style=\"color: #ff9900;\">EXTRACTION</span> <span style=\"color: #3498db;\">AND</span> <span style=\"color: #8e44ad;\">NLP</span> </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26efd8-d3cd-4019-b921-7b8eb392340f",
   "metadata": {},
   "source": [
    "### Importing the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68e6f6db-d547-4089-9a92-cdc7bbc16ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lokesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\lokesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lokesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# Load NLTK resources (you might need to download NLTK resources)\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9f34e-63a2-4e4b-a443-9273f5b6eac9",
   "metadata": {},
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e7e24ac-50fc-4319-90e6-0036a44682fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...\n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...\n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...\n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...\n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...\n",
       "..              ...                                                ...\n",
       "95  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...\n",
       "96  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...\n",
       "97  blackassign0098  https://insights.blackcoffer.com/contribution-...\n",
       "98  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...\n",
       "99  blackassign0100  https://insights.blackcoffer.com/how-will-covi...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel(\"C:\\\\Users\\\\lokesh\\\\Downloads\\\\Input.xlsx\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9124bb0-7f21-435d-b170-e197c75b2841",
   "metadata": {},
   "source": [
    "### Data Extraction and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "997b2093-04f7-47cb-86cf-6480c083768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article blackassign0001 extracted and saved successfully.\n",
      "Article blackassign0002 extracted and saved successfully.\n",
      "Article blackassign0003 extracted and saved successfully.\n",
      "Article blackassign0004 extracted and saved successfully.\n",
      "Article blackassign0005 extracted and saved successfully.\n",
      "Article blackassign0006 extracted and saved successfully.\n",
      "Article blackassign0007 extracted and saved successfully.\n",
      "Article blackassign0008 extracted and saved successfully.\n",
      "Article blackassign0009 extracted and saved successfully.\n",
      "Article blackassign0010 extracted and saved successfully.\n",
      "Article blackassign0011 extracted and saved successfully.\n",
      "Article blackassign0012 extracted and saved successfully.\n",
      "Article blackassign0013 extracted and saved successfully.\n",
      "Failed to extract article blackassign0014.\n",
      "Article blackassign0015 extracted and saved successfully.\n",
      "Article blackassign0016 extracted and saved successfully.\n",
      "Article blackassign0017 extracted and saved successfully.\n",
      "Article blackassign0018 extracted and saved successfully.\n",
      "Article blackassign0019 extracted and saved successfully.\n",
      "Failed to extract article blackassign0020.\n",
      "Article blackassign0021 extracted and saved successfully.\n",
      "Article blackassign0022 extracted and saved successfully.\n",
      "Article blackassign0023 extracted and saved successfully.\n",
      "Article blackassign0024 extracted and saved successfully.\n",
      "Article blackassign0025 extracted and saved successfully.\n",
      "Article blackassign0026 extracted and saved successfully.\n",
      "Article blackassign0027 extracted and saved successfully.\n",
      "Article blackassign0028 extracted and saved successfully.\n",
      "Failed to extract article blackassign0029.\n",
      "Article blackassign0030 extracted and saved successfully.\n",
      "Article blackassign0031 extracted and saved successfully.\n",
      "Article blackassign0032 extracted and saved successfully.\n",
      "Article blackassign0033 extracted and saved successfully.\n",
      "Article blackassign0034 extracted and saved successfully.\n",
      "Article blackassign0035 extracted and saved successfully.\n",
      "Failed to extract article blackassign0036.\n",
      "Article blackassign0037 extracted and saved successfully.\n",
      "Article blackassign0038 extracted and saved successfully.\n",
      "Article blackassign0039 extracted and saved successfully.\n",
      "Article blackassign0040 extracted and saved successfully.\n",
      "Article blackassign0041 extracted and saved successfully.\n",
      "Article blackassign0042 extracted and saved successfully.\n",
      "Failed to extract article blackassign0043.\n",
      "Article blackassign0044 extracted and saved successfully.\n",
      "Article blackassign0045 extracted and saved successfully.\n",
      "Article blackassign0046 extracted and saved successfully.\n",
      "Article blackassign0047 extracted and saved successfully.\n",
      "Article blackassign0048 extracted and saved successfully.\n",
      "Failed to extract article blackassign0049.\n",
      "Article blackassign0050 extracted and saved successfully.\n",
      "Article blackassign0051 extracted and saved successfully.\n",
      "Article blackassign0052 extracted and saved successfully.\n",
      "Article blackassign0053 extracted and saved successfully.\n",
      "Article blackassign0054 extracted and saved successfully.\n",
      "Article blackassign0055 extracted and saved successfully.\n",
      "Article blackassign0056 extracted and saved successfully.\n",
      "Article blackassign0057 extracted and saved successfully.\n",
      "Article blackassign0058 extracted and saved successfully.\n",
      "Article blackassign0059 extracted and saved successfully.\n",
      "Article blackassign0060 extracted and saved successfully.\n",
      "Article blackassign0061 extracted and saved successfully.\n",
      "Article blackassign0062 extracted and saved successfully.\n",
      "Article blackassign0063 extracted and saved successfully.\n",
      "Article blackassign0064 extracted and saved successfully.\n",
      "Article blackassign0065 extracted and saved successfully.\n",
      "Article blackassign0066 extracted and saved successfully.\n",
      "Article blackassign0067 extracted and saved successfully.\n",
      "Article blackassign0068 extracted and saved successfully.\n",
      "Article blackassign0069 extracted and saved successfully.\n",
      "Article blackassign0070 extracted and saved successfully.\n",
      "Article blackassign0071 extracted and saved successfully.\n",
      "Article blackassign0072 extracted and saved successfully.\n",
      "Article blackassign0073 extracted and saved successfully.\n",
      "Article blackassign0074 extracted and saved successfully.\n",
      "Article blackassign0075 extracted and saved successfully.\n",
      "Article blackassign0076 extracted and saved successfully.\n",
      "Article blackassign0077 extracted and saved successfully.\n",
      "Article blackassign0078 extracted and saved successfully.\n",
      "Article blackassign0079 extracted and saved successfully.\n",
      "Article blackassign0080 extracted and saved successfully.\n",
      "Article blackassign0081 extracted and saved successfully.\n",
      "Article blackassign0082 extracted and saved successfully.\n",
      "Failed to extract article blackassign0083.\n",
      "Failed to extract article blackassign0084.\n",
      "Article blackassign0085 extracted and saved successfully.\n",
      "Article blackassign0086 extracted and saved successfully.\n",
      "Article blackassign0087 extracted and saved successfully.\n",
      "Article blackassign0088 extracted and saved successfully.\n",
      "Article blackassign0089 extracted and saved successfully.\n",
      "Article blackassign0090 extracted and saved successfully.\n",
      "Article blackassign0091 extracted and saved successfully.\n",
      "Failed to extract article blackassign0092.\n",
      "Article blackassign0093 extracted and saved successfully.\n",
      "Article blackassign0094 extracted and saved successfully.\n",
      "Article blackassign0095 extracted and saved successfully.\n",
      "Article blackassign0096 extracted and saved successfully.\n",
      "Article blackassign0097 extracted and saved successfully.\n",
      "Article blackassign0098 extracted and saved successfully.\n",
      "Failed to extract article blackassign0099.\n",
      "Failed to extract article blackassign0100.\n",
      "CPU times: total: 57.9 s\n",
      "Wall time: 13min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This magic funtion is used to prin the execution of the time\n",
    "# Function to extract the article title and text from a URLs given in Input.xlxs file and extracting each articles into txt file\n",
    "\n",
    "def extract_article_text(url):\n",
    "    try:\n",
    "        response=requests.get(url)\n",
    "        soup=BeautifulSoup(response.text,'html.parser')\n",
    "        \n",
    "        # Find and remove unwanted elements (e.g., header, footer, etc.)\n",
    "        for element in soup([\"header\",\"footer\"]):\n",
    "            element.decompose()\n",
    "        \n",
    "        # Extract article title and text\n",
    "        article_title=soup.find('title').text.strip()\n",
    "        article_text=\"\"\n",
    "        \n",
    "        # Extract text from <div class=\"td-post-content tagdiv-type\">\n",
    "        article_div=soup.find('div',class_='td-post-content tagdiv-type')\n",
    "        if article_div:\n",
    "            article_text=article_div.get_text()\n",
    "        return article_title,article_text\n",
    "    \n",
    "    except Exception:\n",
    "        print(f\"Error while extracting article from {url}: {Exception}\")\n",
    "        return None,None\n",
    "\n",
    "# Function to save the article title and text to a text file\n",
    "def save_article_to_file(url_id,article_title,article_text):\n",
    "    if not os.path.exists(\"articles\"):\n",
    "        os.mkdir(\"articles\")\n",
    "    with open(f\"articles/{url_id}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Title:{article_title}\\n\\n\")\n",
    "        file.write(article_text)\n",
    "def main():\n",
    "    input_file=\"C:\\\\Users\\\\lokesh\\\\Downloads\\\\Input.xlsx\"\n",
    "    df=pd.read_excel(input_file)\n",
    "    for index, row in df.iterrows():\n",
    "        url_id=row[\"URL_ID\"]\n",
    "        url=row[\"URL\"]\n",
    " \n",
    "        # Extract article title and text4\n",
    "        article_title,article_text=extract_article_text(url)\n",
    "\n",
    "        # Check if extraction was successful\n",
    "        if article_title and article_text:\n",
    "            save_article_to_file(url_id,article_title,article_text)\n",
    "            print(f\"Article {url_id} extracted and saved successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to extract article {url_id}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc9595c-5fe8-4ab1-85c5-a6f94db14020",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89330392-3758-40f7-9c74-3bc02cde0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load positive and negative dictionaries from files\n",
    "def load_dictionaries(positive_dict_file,negative_dict_file):\n",
    "    with open(positive_dict_file,'r') as file:\n",
    "        positive_words=set(file.read().splitlines())\n",
    "    with open(negative_dict_file,'r') as file:\n",
    "        negative_words=set(file.read().splitlines())\n",
    "    return positive_words,negative_words\n",
    "\n",
    "# Function to perform sentiment analysis and calculate scores\n",
    "def calculate_sentiment_scores(text, positive_words,negative_words):\n",
    "    sia=SentimentIntensityAnalyzer()\n",
    "    tokens=word_tokenize(text)\n",
    "    positive_score=0\n",
    "    negative_score=0\n",
    "    for word in tokens:\n",
    "        # Remove punctuation and convert to lowercase\n",
    "        word=word.lower()\n",
    "        if word.isalpha():\n",
    "            # Check if the word is in the positive dictionary\n",
    "            if word in positive_words:\n",
    "                positive_score+=1\n",
    "            # Check if the word is in the negative dictionary\n",
    "            if word in negative_words:\n",
    "                negative_score+=1\n",
    "    \n",
    "    # Calculate sentiment analysis metrics\n",
    "    polarity_score=(positive_score-negative_score)/((positive_score+negative_score)+0.000001)\n",
    "    subjectivity_score=(positive_score+negative_score)/(len(tokens)+0.000001)\n",
    "    return positive_score,negative_score,polarity_score,subjectivity_score\n",
    "\n",
    "def main():\n",
    "    input_data_file=\"C:\\\\Users\\\\lokesh\\\\Downloads\\\\20211030 Test Assignment-20240604T071155Z-001\\\\20211030 Test Assignment\\\\Output Data Structure.xlsx\"\n",
    "    positive_dict_file=\"C:\\\\Users\\\\lokesh\\\\Downloads\\\\20211030 Test Assignment-20240604T071155Z-001\\\\20211030 Test Assignment\\\\MasterDictionary\\\\positive-words.txt\"\n",
    "    negative_dict_file=\"C:\\\\Users\\\\lokesh\\\\Downloads\\\\20211030 Test Assignment-20240604T071155Z-001\\\\20211030 Test Assignment\\\\MasterDictionary\\\\negative-words.txt\"\n",
    "    articles_dir=\"articles\"\n",
    "    \n",
    "    # Load dictionaries\n",
    "    positive_words,negative_words=load_dictionaries(positive_dict_file,negative_dict_file)\n",
    "\n",
    "    # Read output data structure Excel file\n",
    "    output_data=pd.read_excel(input_data_file)\n",
    "    results=[]\n",
    "    for index,row in output_data.iterrows():\n",
    "        url_id=row[\"URL_ID\"]\n",
    "        url=row[\"URL\"]\n",
    "        article_file=os.path.join(articles_dir,f\"{url_id}.txt\")\n",
    "        if os.path.exists(article_file):\n",
    "            # Read article text from file\n",
    "            with open(article_file,'r',encoding='utf-8') as article:\n",
    "                article_text=article.read()\n",
    "            # Perform sentiment analysis\n",
    "            positive_score, negative_score, polarity_score, subjectivity_score = calculate_sentiment_scores(article_text, positive_words, negative_words)\n",
    "            results.append({\n",
    "                \"URL_ID\":url_id,\n",
    "                \"URL\":url,\n",
    "                \"Positive_Score\":positive_score,\n",
    "                \"Negative_Score\":negative_score,\n",
    "                \"Polarity_Score\":polarity_score,\n",
    "                \"Subjectivity_Score\":subjectivity_score\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    result_df=pd.DataFrame(results)\n",
    "    \n",
    "    # Save results to Excel\n",
    "    result_df.to_excel(\"sentiment_analysis_results.xlsx\",index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a3f46e-5af0-4a39-bfd1-b1b37a6ad77e",
   "metadata": {},
   "source": [
    "### Sentiment Analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58efc405-7c35-4265-a354-124d82c0bf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Polarity_Score</th>\n",
       "      <th>Subjectivity_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.035765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>64</td>\n",
       "      <td>31</td>\n",
       "      <td>0.347368</td>\n",
       "      <td>0.055458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.051780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>39</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>0.092457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.041078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>blackassign0094</td>\n",
       "      <td>https://insights.blackcoffer.com/gaming-disord...</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>0.064319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>blackassign0095</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>0.051007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>30</td>\n",
       "      <td>57</td>\n",
       "      <td>-0.310345</td>\n",
       "      <td>0.070789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.044776</td>\n",
       "      <td>0.054828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.022272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "84  blackassign0094  https://insights.blackcoffer.com/gaming-disord...   \n",
       "85  blackassign0095  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "86  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "87  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "88  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "\n",
       "    Positive_Score  Negative_Score  Polarity_Score  Subjectivity_Score  \n",
       "0               44               6        0.760000            0.035765  \n",
       "1               64              31        0.347368            0.055458  \n",
       "2               40              24        0.250000            0.051780  \n",
       "3               39              75       -0.315789            0.092457  \n",
       "4               24               8        0.500000            0.041078  \n",
       "..             ...             ...             ...                 ...  \n",
       "84              34              50       -0.190476            0.064319  \n",
       "85              13              25       -0.315789            0.051007  \n",
       "86              30              57       -0.310345            0.070789  \n",
       "87              32              35       -0.044776            0.054828  \n",
       "88               7               3        0.400000            0.022272  \n",
       "\n",
       "[89 rows x 6 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis=pd.read_excel(\"sentiment_analysis_results.xlsx\")\n",
    "sentiment_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8d4d5-1045-41fc-b229-2fe8c39234b6",
   "metadata": {},
   "source": [
    "### Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5efc08a0-2b8c-4722-98fd-8703f48f1ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate average sentence length\n",
    "def calculate_avg_sentence_length(sentences):\n",
    "    total_words=sum(len(word_tokenize(sentence)) for sentence in sentences)\n",
    "    total_sentences=len(sentences)\n",
    "    return total_words/total_sentences\n",
    "\n",
    "# Function to calculate percentage of complex words\n",
    "def calculate_percentage_complex_words(text):\n",
    "    words=word_tokenize(text)\n",
    "    complex_words=[word for word in words if len(word)>2]\n",
    "    return len(complex_words)/len(words)\n",
    "\n",
    "# Function to calculate fog index\n",
    "def calculate_fog_index(avg_sentence_length,percentage_complex_words):\n",
    "    return 0.4*(avg_sentence_length+percentage_complex_words)\n",
    "\n",
    "# Function to calculate average number of words per sentence\n",
    "def calculate_avg_words_per_sentence(words,sentences):\n",
    "    return len(words)/len(sentences)\n",
    "\n",
    "# Function to calculate complex word count\n",
    "def calculate_complex_word_count(text):\n",
    "    words=word_tokenize(text)\n",
    "    complex_words=[word for word in words if len(word)>2]\n",
    "    return len(complex_words)\n",
    "\n",
    "# Function to calculate word count\n",
    "def calculate_word_count(text):\n",
    "    words=word_tokenize(text)\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    cleaned_words=[word for word in words if word not in stop_words and word.isalpha()]\n",
    "    return len(cleaned_words)\n",
    "\n",
    "# Function to count syllables in a word\n",
    "def count_syllables(word):\n",
    "    vowels=\"AEIOUaeiou\"\n",
    "    count=0\n",
    "    if word[-1] in ['E','eE'] and word[-2:]!='LE' and word[-2:]!='le':\n",
    "        word=word[:-1]\n",
    "    for index,letter in enumerate(word):\n",
    "        if index==0 and letter in vowels:\n",
    "            count+=1\n",
    "        elif letter in vowels and word[index-1] not in vowels:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "# Function to calculate syllable count per word\n",
    "def calculate_syllable_count_per_word(text):\n",
    "    words=word_tokenize(text)\n",
    "    syllable_count=sum(count_syllables(word) for word in words)\n",
    "    return syllable_count/len(words)\n",
    "\n",
    "# Function to calculate personal pronoun count\n",
    "def calculate_personal_pronouns(text):\n",
    "    pronouns=[\"I\",\"we\",\"my\",\"ours\",\"us\"]\n",
    "    pattern=r'\\b(?:'+'|'.join(pronouns)+r')\\b'\n",
    "    matches=re.findall(pattern,text)\n",
    "    return len(matches)\n",
    "\n",
    "# Function to calculate average word length\n",
    "def calculate_avg_word_length(text):\n",
    "    words=word_tokenize(text)\n",
    "    total_characters=sum(len(word) for word in words)\n",
    "    return total_characters/len(words)\n",
    "\n",
    "def main():\n",
    "    output_data_file=\"C:\\\\Users\\\\lokesh\\\\Downloads\\\\20211030 Test Assignment-20240604T071155Z-001\\\\20211030 Test Assignment\\\\Output Data Structure.xlsx\"\n",
    "    articles_dir=\"articles\"\n",
    "    \n",
    "    # Read output data structure Excel file\n",
    "    output_data=pd.read_excel(output_data_file)\n",
    "    results_=[]\n",
    "    for index,row in output_data.iterrows():\n",
    "        url_id=row[\"URL_ID\"]\n",
    "        article_file=os.path.join(articles_dir,f\"{url_id}.txt\")\n",
    "        if os.path.exists(article_file):\n",
    "           \n",
    "            # Read article text from file\n",
    "            with open(article_file,'r',encoding='utf-8') as article:\n",
    "                article_text=article.read()\n",
    "            # Tokenize sentences for text analysis\n",
    "            sentences=sent_tokenize(article_text)\n",
    "            words=word_tokenize(article_text)\n",
    "        \n",
    "            # Calculate text analysis metrics\n",
    "            avg_sentence_length=calculate_avg_sentence_length(sentences)\n",
    "            percentage_complex_words=calculate_percentage_complex_words(article_text)\n",
    "            fog_index=calculate_fog_index(avg_sentence_length, percentage_complex_words)\n",
    "            avg_words_per_sentence=calculate_avg_words_per_sentence(words, sentences)\n",
    "            complex_word_count=calculate_complex_word_count(article_text)\n",
    "            word_count=calculate_word_count(article_text)\n",
    "            syllable_count_per_word=calculate_syllable_count_per_word(article_text)\n",
    "            personal_pronoun_count=calculate_personal_pronouns(article_text)\n",
    "            avg_word_length=calculate_avg_word_length(article_text)\n",
    "            results_.append({\n",
    "                \"URL_ID\":url_id,\n",
    "                \"Avg_Sentence_Length\":avg_sentence_length,\n",
    "                \"Percentage_Complex_Words\":percentage_complex_words,\n",
    "                \"Fog_Index\":fog_index,\n",
    "                \"Avg_Words_Per_Sentence\":avg_words_per_sentence,\n",
    "                \"Complex_Word_Count\":complex_word_count,\n",
    "                \"Word_Count\":word_count,\n",
    "                \"Syllable_Count_Per_Word\":syllable_count_per_word,\n",
    "                \"Personal_Pronoun_Count\":personal_pronoun_count,\n",
    "                \"Avg_Word_Length\":avg_word_length\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    result_df2=pd.DataFrame(results_)\n",
    "    \n",
    "    # Save results to Excel\n",
    "    result_df2.to_excel(\"text_analysis_results.xlsx\",index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a8228-0704-47f4-b01b-66a6041b41a4",
   "metadata": {},
   "source": [
    "### Text Analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d397861-4324-46d5-afb5-b729481d20bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>Avg_Sentence_Length</th>\n",
       "      <th>Percentage_Complex_Words</th>\n",
       "      <th>Fog_Index</th>\n",
       "      <th>Avg_Words_Per_Sentence</th>\n",
       "      <th>Complex_Word_Count</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Syllable_Count_Per_Word</th>\n",
       "      <th>Personal_Pronoun_Count</th>\n",
       "      <th>Avg_Word_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>17.696203</td>\n",
       "      <td>0.671674</td>\n",
       "      <td>7.347151</td>\n",
       "      <td>17.696203</td>\n",
       "      <td>939</td>\n",
       "      <td>733</td>\n",
       "      <td>1.413448</td>\n",
       "      <td>6</td>\n",
       "      <td>4.195994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>21.412500</td>\n",
       "      <td>0.717455</td>\n",
       "      <td>8.851982</td>\n",
       "      <td>21.412500</td>\n",
       "      <td>1229</td>\n",
       "      <td>896</td>\n",
       "      <td>1.653824</td>\n",
       "      <td>3</td>\n",
       "      <td>4.872154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>21.684211</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>8.967859</td>\n",
       "      <td>21.684211</td>\n",
       "      <td>909</td>\n",
       "      <td>696</td>\n",
       "      <td>1.875405</td>\n",
       "      <td>13</td>\n",
       "      <td>5.492718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>23.711538</td>\n",
       "      <td>0.716139</td>\n",
       "      <td>9.771071</td>\n",
       "      <td>23.711538</td>\n",
       "      <td>883</td>\n",
       "      <td>690</td>\n",
       "      <td>1.742903</td>\n",
       "      <td>4</td>\n",
       "      <td>5.298459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>19.475000</td>\n",
       "      <td>0.752246</td>\n",
       "      <td>8.090899</td>\n",
       "      <td>19.475000</td>\n",
       "      <td>586</td>\n",
       "      <td>426</td>\n",
       "      <td>1.658537</td>\n",
       "      <td>6</td>\n",
       "      <td>5.077022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>blackassign0094</td>\n",
       "      <td>20.406250</td>\n",
       "      <td>0.702910</td>\n",
       "      <td>8.443664</td>\n",
       "      <td>20.406250</td>\n",
       "      <td>918</td>\n",
       "      <td>666</td>\n",
       "      <td>1.475498</td>\n",
       "      <td>11</td>\n",
       "      <td>4.376723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>blackassign0095</td>\n",
       "      <td>20.694444</td>\n",
       "      <td>0.693960</td>\n",
       "      <td>8.555362</td>\n",
       "      <td>20.694444</td>\n",
       "      <td>517</td>\n",
       "      <td>374</td>\n",
       "      <td>1.477852</td>\n",
       "      <td>4</td>\n",
       "      <td>4.495302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>24.580000</td>\n",
       "      <td>0.739626</td>\n",
       "      <td>10.127850</td>\n",
       "      <td>24.580000</td>\n",
       "      <td>909</td>\n",
       "      <td>657</td>\n",
       "      <td>1.661513</td>\n",
       "      <td>2</td>\n",
       "      <td>4.943857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>0.711948</td>\n",
       "      <td>12.818112</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>870</td>\n",
       "      <td>539</td>\n",
       "      <td>1.450082</td>\n",
       "      <td>5</td>\n",
       "      <td>4.327332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>37.416667</td>\n",
       "      <td>0.734967</td>\n",
       "      <td>15.260653</td>\n",
       "      <td>37.416667</td>\n",
       "      <td>330</td>\n",
       "      <td>248</td>\n",
       "      <td>1.652561</td>\n",
       "      <td>0</td>\n",
       "      <td>5.118040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID  Avg_Sentence_Length  Percentage_Complex_Words  Fog_Index  \\\n",
       "0   blackassign0001            17.696203                  0.671674   7.347151   \n",
       "1   blackassign0002            21.412500                  0.717455   8.851982   \n",
       "2   blackassign0003            21.684211                  0.735437   8.967859   \n",
       "3   blackassign0004            23.711538                  0.716139   9.771071   \n",
       "4   blackassign0005            19.475000                  0.752246   8.090899   \n",
       "..              ...                  ...                       ...        ...   \n",
       "84  blackassign0094            20.406250                  0.702910   8.443664   \n",
       "85  blackassign0095            20.694444                  0.693960   8.555362   \n",
       "86  blackassign0096            24.580000                  0.739626  10.127850   \n",
       "87  blackassign0097            31.333333                  0.711948  12.818112   \n",
       "88  blackassign0098            37.416667                  0.734967  15.260653   \n",
       "\n",
       "    Avg_Words_Per_Sentence  Complex_Word_Count  Word_Count  \\\n",
       "0                17.696203                 939         733   \n",
       "1                21.412500                1229         896   \n",
       "2                21.684211                 909         696   \n",
       "3                23.711538                 883         690   \n",
       "4                19.475000                 586         426   \n",
       "..                     ...                 ...         ...   \n",
       "84               20.406250                 918         666   \n",
       "85               20.694444                 517         374   \n",
       "86               24.580000                 909         657   \n",
       "87               31.333333                 870         539   \n",
       "88               37.416667                 330         248   \n",
       "\n",
       "    Syllable_Count_Per_Word  Personal_Pronoun_Count  Avg_Word_Length  \n",
       "0                  1.413448                       6         4.195994  \n",
       "1                  1.653824                       3         4.872154  \n",
       "2                  1.875405                      13         5.492718  \n",
       "3                  1.742903                       4         5.298459  \n",
       "4                  1.658537                       6         5.077022  \n",
       "..                      ...                     ...              ...  \n",
       "84                 1.475498                      11         4.376723  \n",
       "85                 1.477852                       4         4.495302  \n",
       "86                 1.661513                       2         4.943857  \n",
       "87                 1.450082                       5         4.327332  \n",
       "88                 1.652561                       0         5.118040  \n",
       "\n",
       "[89 rows x 10 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_analysis=pd.read_excel(\"text_analysis_results.xlsx\")\n",
    "text_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b3de3-9447-4fe9-bd85-4d2d71bcd238",
   "metadata": {},
   "source": [
    "### Merge the Sentiment Analysis and Text Analysis data Based on the URL ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5a13289-dbf6-49dc-b0db-a024b8efa9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Polarity_Score</th>\n",
       "      <th>Subjectivity_Score</th>\n",
       "      <th>Avg_Sentence_Length</th>\n",
       "      <th>Percentage_Complex_Words</th>\n",
       "      <th>Fog_Index</th>\n",
       "      <th>Avg_Words_Per_Sentence</th>\n",
       "      <th>Complex_Word_Count</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Syllable_Count_Per_Word</th>\n",
       "      <th>Personal_Pronoun_Count</th>\n",
       "      <th>Avg_Word_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.035765</td>\n",
       "      <td>17.696203</td>\n",
       "      <td>0.671674</td>\n",
       "      <td>7.347151</td>\n",
       "      <td>17.696203</td>\n",
       "      <td>939</td>\n",
       "      <td>733</td>\n",
       "      <td>1.413448</td>\n",
       "      <td>6</td>\n",
       "      <td>4.195994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>64</td>\n",
       "      <td>31</td>\n",
       "      <td>0.347368</td>\n",
       "      <td>0.055458</td>\n",
       "      <td>21.412500</td>\n",
       "      <td>0.717455</td>\n",
       "      <td>8.851982</td>\n",
       "      <td>21.412500</td>\n",
       "      <td>1229</td>\n",
       "      <td>896</td>\n",
       "      <td>1.653824</td>\n",
       "      <td>3</td>\n",
       "      <td>4.872154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.051780</td>\n",
       "      <td>21.684211</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>8.967859</td>\n",
       "      <td>21.684211</td>\n",
       "      <td>909</td>\n",
       "      <td>696</td>\n",
       "      <td>1.875405</td>\n",
       "      <td>13</td>\n",
       "      <td>5.492718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>39</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>0.092457</td>\n",
       "      <td>23.711538</td>\n",
       "      <td>0.716139</td>\n",
       "      <td>9.771071</td>\n",
       "      <td>23.711538</td>\n",
       "      <td>883</td>\n",
       "      <td>690</td>\n",
       "      <td>1.742903</td>\n",
       "      <td>4</td>\n",
       "      <td>5.298459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.041078</td>\n",
       "      <td>19.475000</td>\n",
       "      <td>0.752246</td>\n",
       "      <td>8.090899</td>\n",
       "      <td>19.475000</td>\n",
       "      <td>586</td>\n",
       "      <td>426</td>\n",
       "      <td>1.658537</td>\n",
       "      <td>6</td>\n",
       "      <td>5.077022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>blackassign0094</td>\n",
       "      <td>https://insights.blackcoffer.com/gaming-disord...</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>0.064319</td>\n",
       "      <td>20.406250</td>\n",
       "      <td>0.702910</td>\n",
       "      <td>8.443664</td>\n",
       "      <td>20.406250</td>\n",
       "      <td>918</td>\n",
       "      <td>666</td>\n",
       "      <td>1.475498</td>\n",
       "      <td>11</td>\n",
       "      <td>4.376723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>blackassign0095</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>0.051007</td>\n",
       "      <td>20.694444</td>\n",
       "      <td>0.693960</td>\n",
       "      <td>8.555362</td>\n",
       "      <td>20.694444</td>\n",
       "      <td>517</td>\n",
       "      <td>374</td>\n",
       "      <td>1.477852</td>\n",
       "      <td>4</td>\n",
       "      <td>4.495302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>30</td>\n",
       "      <td>57</td>\n",
       "      <td>-0.310345</td>\n",
       "      <td>0.070789</td>\n",
       "      <td>24.580000</td>\n",
       "      <td>0.739626</td>\n",
       "      <td>10.127850</td>\n",
       "      <td>24.580000</td>\n",
       "      <td>909</td>\n",
       "      <td>657</td>\n",
       "      <td>1.661513</td>\n",
       "      <td>2</td>\n",
       "      <td>4.943857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.044776</td>\n",
       "      <td>0.054828</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>0.711948</td>\n",
       "      <td>12.818112</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>870</td>\n",
       "      <td>539</td>\n",
       "      <td>1.450082</td>\n",
       "      <td>5</td>\n",
       "      <td>4.327332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>37.416667</td>\n",
       "      <td>0.734967</td>\n",
       "      <td>15.260653</td>\n",
       "      <td>37.416667</td>\n",
       "      <td>330</td>\n",
       "      <td>248</td>\n",
       "      <td>1.652561</td>\n",
       "      <td>0</td>\n",
       "      <td>5.118040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "84  blackassign0094  https://insights.blackcoffer.com/gaming-disord...   \n",
       "85  blackassign0095  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "86  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "87  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "88  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "\n",
       "    Positive_Score  Negative_Score  Polarity_Score  Subjectivity_Score  \\\n",
       "0               44               6        0.760000            0.035765   \n",
       "1               64              31        0.347368            0.055458   \n",
       "2               40              24        0.250000            0.051780   \n",
       "3               39              75       -0.315789            0.092457   \n",
       "4               24               8        0.500000            0.041078   \n",
       "..             ...             ...             ...                 ...   \n",
       "84              34              50       -0.190476            0.064319   \n",
       "85              13              25       -0.315789            0.051007   \n",
       "86              30              57       -0.310345            0.070789   \n",
       "87              32              35       -0.044776            0.054828   \n",
       "88               7               3        0.400000            0.022272   \n",
       "\n",
       "    Avg_Sentence_Length  Percentage_Complex_Words  Fog_Index  \\\n",
       "0             17.696203                  0.671674   7.347151   \n",
       "1             21.412500                  0.717455   8.851982   \n",
       "2             21.684211                  0.735437   8.967859   \n",
       "3             23.711538                  0.716139   9.771071   \n",
       "4             19.475000                  0.752246   8.090899   \n",
       "..                  ...                       ...        ...   \n",
       "84            20.406250                  0.702910   8.443664   \n",
       "85            20.694444                  0.693960   8.555362   \n",
       "86            24.580000                  0.739626  10.127850   \n",
       "87            31.333333                  0.711948  12.818112   \n",
       "88            37.416667                  0.734967  15.260653   \n",
       "\n",
       "    Avg_Words_Per_Sentence  Complex_Word_Count  Word_Count  \\\n",
       "0                17.696203                 939         733   \n",
       "1                21.412500                1229         896   \n",
       "2                21.684211                 909         696   \n",
       "3                23.711538                 883         690   \n",
       "4                19.475000                 586         426   \n",
       "..                     ...                 ...         ...   \n",
       "84               20.406250                 918         666   \n",
       "85               20.694444                 517         374   \n",
       "86               24.580000                 909         657   \n",
       "87               31.333333                 870         539   \n",
       "88               37.416667                 330         248   \n",
       "\n",
       "    Syllable_Count_Per_Word  Personal_Pronoun_Count  Avg_Word_Length  \n",
       "0                  1.413448                       6         4.195994  \n",
       "1                  1.653824                       3         4.872154  \n",
       "2                  1.875405                      13         5.492718  \n",
       "3                  1.742903                       4         5.298459  \n",
       "4                  1.658537                       6         5.077022  \n",
       "..                      ...                     ...              ...  \n",
       "84                 1.475498                      11         4.376723  \n",
       "85                 1.477852                       4         4.495302  \n",
       "86                 1.661513                       2         4.943857  \n",
       "87                 1.450082                       5         4.327332  \n",
       "88                 1.652561                       0         5.118040  \n",
       "\n",
       "[89 rows x 15 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df=pd.merge(sentiment_analysis, text_analysis, on='URL_ID')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5655d54-b41e-4a63-93ce-10bf59416119",
   "metadata": {},
   "source": [
    "### Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "627c8f18-fd46-4881-a4d0-c21530c31fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Polarity_Score</th>\n",
       "      <th>Subjectivity_Score</th>\n",
       "      <th>Avg_Sentence_Length</th>\n",
       "      <th>Percentage_Complex_Words</th>\n",
       "      <th>Fog_Index</th>\n",
       "      <th>Avg_Words_Per_Sentence</th>\n",
       "      <th>Complex_Word_Count</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Syllable_Count_Per_Word</th>\n",
       "      <th>Personal_Pronoun_Count</th>\n",
       "      <th>Avg_Word_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.035765</td>\n",
       "      <td>17.696203</td>\n",
       "      <td>0.671674</td>\n",
       "      <td>7.347151</td>\n",
       "      <td>17.696203</td>\n",
       "      <td>939</td>\n",
       "      <td>733</td>\n",
       "      <td>1.413448</td>\n",
       "      <td>6</td>\n",
       "      <td>4.195994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>64</td>\n",
       "      <td>31</td>\n",
       "      <td>0.347368</td>\n",
       "      <td>0.055458</td>\n",
       "      <td>21.412500</td>\n",
       "      <td>0.717455</td>\n",
       "      <td>8.851982</td>\n",
       "      <td>21.412500</td>\n",
       "      <td>1229</td>\n",
       "      <td>896</td>\n",
       "      <td>1.653824</td>\n",
       "      <td>3</td>\n",
       "      <td>4.872154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.051780</td>\n",
       "      <td>21.684211</td>\n",
       "      <td>0.735437</td>\n",
       "      <td>8.967859</td>\n",
       "      <td>21.684211</td>\n",
       "      <td>909</td>\n",
       "      <td>696</td>\n",
       "      <td>1.875405</td>\n",
       "      <td>13</td>\n",
       "      <td>5.492718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>39</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>0.092457</td>\n",
       "      <td>23.711538</td>\n",
       "      <td>0.716139</td>\n",
       "      <td>9.771071</td>\n",
       "      <td>23.711538</td>\n",
       "      <td>883</td>\n",
       "      <td>690</td>\n",
       "      <td>1.742903</td>\n",
       "      <td>4</td>\n",
       "      <td>5.298459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.041078</td>\n",
       "      <td>19.475000</td>\n",
       "      <td>0.752246</td>\n",
       "      <td>8.090899</td>\n",
       "      <td>19.475000</td>\n",
       "      <td>586</td>\n",
       "      <td>426</td>\n",
       "      <td>1.658537</td>\n",
       "      <td>6</td>\n",
       "      <td>5.077022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>blackassign0094</td>\n",
       "      <td>https://insights.blackcoffer.com/gaming-disord...</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>0.064319</td>\n",
       "      <td>20.406250</td>\n",
       "      <td>0.702910</td>\n",
       "      <td>8.443664</td>\n",
       "      <td>20.406250</td>\n",
       "      <td>918</td>\n",
       "      <td>666</td>\n",
       "      <td>1.475498</td>\n",
       "      <td>11</td>\n",
       "      <td>4.376723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>blackassign0095</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>0.051007</td>\n",
       "      <td>20.694444</td>\n",
       "      <td>0.693960</td>\n",
       "      <td>8.555362</td>\n",
       "      <td>20.694444</td>\n",
       "      <td>517</td>\n",
       "      <td>374</td>\n",
       "      <td>1.477852</td>\n",
       "      <td>4</td>\n",
       "      <td>4.495302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>30</td>\n",
       "      <td>57</td>\n",
       "      <td>-0.310345</td>\n",
       "      <td>0.070789</td>\n",
       "      <td>24.580000</td>\n",
       "      <td>0.739626</td>\n",
       "      <td>10.127850</td>\n",
       "      <td>24.580000</td>\n",
       "      <td>909</td>\n",
       "      <td>657</td>\n",
       "      <td>1.661513</td>\n",
       "      <td>2</td>\n",
       "      <td>4.943857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.044776</td>\n",
       "      <td>0.054828</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>0.711948</td>\n",
       "      <td>12.818112</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>870</td>\n",
       "      <td>539</td>\n",
       "      <td>1.450082</td>\n",
       "      <td>5</td>\n",
       "      <td>4.327332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>37.416667</td>\n",
       "      <td>0.734967</td>\n",
       "      <td>15.260653</td>\n",
       "      <td>37.416667</td>\n",
       "      <td>330</td>\n",
       "      <td>248</td>\n",
       "      <td>1.652561</td>\n",
       "      <td>0</td>\n",
       "      <td>5.118040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0           URL_ID  \\\n",
       "0            0  blackassign0001   \n",
       "1            1  blackassign0002   \n",
       "2            2  blackassign0003   \n",
       "3            3  blackassign0004   \n",
       "4            4  blackassign0005   \n",
       "..         ...              ...   \n",
       "84          84  blackassign0094   \n",
       "85          85  blackassign0095   \n",
       "86          86  blackassign0096   \n",
       "87          87  blackassign0097   \n",
       "88          88  blackassign0098   \n",
       "\n",
       "                                                  URL  Positive_Score  \\\n",
       "0   https://insights.blackcoffer.com/rising-it-cit...              44   \n",
       "1   https://insights.blackcoffer.com/rising-it-cit...              64   \n",
       "2   https://insights.blackcoffer.com/internet-dema...              40   \n",
       "3   https://insights.blackcoffer.com/rise-of-cyber...              39   \n",
       "4   https://insights.blackcoffer.com/ott-platform-...              24   \n",
       "..                                                ...             ...   \n",
       "84  https://insights.blackcoffer.com/gaming-disord...              34   \n",
       "85  https://insights.blackcoffer.com/what-is-the-r...              13   \n",
       "86  https://insights.blackcoffer.com/what-is-the-r...              30   \n",
       "87  https://insights.blackcoffer.com/impact-of-cov...              32   \n",
       "88  https://insights.blackcoffer.com/contribution-...               7   \n",
       "\n",
       "    Negative_Score  Polarity_Score  Subjectivity_Score  Avg_Sentence_Length  \\\n",
       "0                6        0.760000            0.035765            17.696203   \n",
       "1               31        0.347368            0.055458            21.412500   \n",
       "2               24        0.250000            0.051780            21.684211   \n",
       "3               75       -0.315789            0.092457            23.711538   \n",
       "4                8        0.500000            0.041078            19.475000   \n",
       "..             ...             ...                 ...                  ...   \n",
       "84              50       -0.190476            0.064319            20.406250   \n",
       "85              25       -0.315789            0.051007            20.694444   \n",
       "86              57       -0.310345            0.070789            24.580000   \n",
       "87              35       -0.044776            0.054828            31.333333   \n",
       "88               3        0.400000            0.022272            37.416667   \n",
       "\n",
       "    Percentage_Complex_Words  Fog_Index  Avg_Words_Per_Sentence  \\\n",
       "0                   0.671674   7.347151               17.696203   \n",
       "1                   0.717455   8.851982               21.412500   \n",
       "2                   0.735437   8.967859               21.684211   \n",
       "3                   0.716139   9.771071               23.711538   \n",
       "4                   0.752246   8.090899               19.475000   \n",
       "..                       ...        ...                     ...   \n",
       "84                  0.702910   8.443664               20.406250   \n",
       "85                  0.693960   8.555362               20.694444   \n",
       "86                  0.739626  10.127850               24.580000   \n",
       "87                  0.711948  12.818112               31.333333   \n",
       "88                  0.734967  15.260653               37.416667   \n",
       "\n",
       "    Complex_Word_Count  Word_Count  Syllable_Count_Per_Word  \\\n",
       "0                  939         733                 1.413448   \n",
       "1                 1229         896                 1.653824   \n",
       "2                  909         696                 1.875405   \n",
       "3                  883         690                 1.742903   \n",
       "4                  586         426                 1.658537   \n",
       "..                 ...         ...                      ...   \n",
       "84                 918         666                 1.475498   \n",
       "85                 517         374                 1.477852   \n",
       "86                 909         657                 1.661513   \n",
       "87                 870         539                 1.450082   \n",
       "88                 330         248                 1.652561   \n",
       "\n",
       "    Personal_Pronoun_Count  Avg_Word_Length  \n",
       "0                        6         4.195994  \n",
       "1                        3         4.872154  \n",
       "2                       13         5.492718  \n",
       "3                        4         5.298459  \n",
       "4                        6         5.077022  \n",
       "..                     ...              ...  \n",
       "84                      11         4.376723  \n",
       "85                       4         4.495302  \n",
       "86                       2         4.943857  \n",
       "87                       5         4.327332  \n",
       "88                       0         5.118040  \n",
       "\n",
       "[89 rows x 16 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.to_excel(\"OutputDataStructure.xlsx\")\n",
    "output=pd.read_excel(\"OutputDataStructure.xlsx\")\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
